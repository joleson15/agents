{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896f56bc",
   "metadata": {},
   "source": [
    "# A2A - a thread:\n",
    "\n",
    "### What is A2A?\n",
    "A2A is a protocol to allow AI agents to communicate autonomously amongst themselves in a standardized way. It was introduced by Google in April 2025 and donated to the Linux Foundation for more widespread adoption. As the sophistication of AI systems grows, so has the ability to automate daily tasks. However, scaling multi-agent systems has been a major bottleneck for many engineers. Frameworks like langgraph seek to solve this problem, but the framework is not very scalable and the api's don't always fit the needs of developers, can become outdated, and may introduce breaking changes...hence the need for custom agents, and modularity. A2A is an effort by Google to standardize inter-agent communication and allow developers to integrate the capabilities of various frameworks. \n",
    "\n",
    "The probabalistic origins of machine learning and AI models cause a significant amount of non-determinism in the outputs, on the contrary to traditional algorithms that provide a deterministic output (i.e. given the same input, it always produces the same output). Because of this, we can't always predict the output of a machine learning algorithm. So maybe it is obvious that in order to allow these systems to share information, the outputs must be wrapped in some metadata to provide some scaffolding for a message format, even though the messages themselves are always unique. \n",
    "\n",
    "\n",
    "See also MCP, a protocol introduced by Anthropic to provide a standard of communication between AI models and tools, data, prompts, and other resources. While MCP allows the AI \"agent\" external functionality like querying a database, searching the internet, or executing a workflow, A2A allows multiple specialized AI agents to communicate with each other and complete complex tasks by utilizing their variety of skills. If the A2A protocol reaches a critical mass, it will hopefully become the de-facto standard of communication for the new era of intelligent systems\n",
    "\n",
    "Example: Google Search Agent, Database Query agent, summarizer agent, analysis agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec7194",
   "metadata": {},
   "source": [
    "### The Agent\n",
    "\n",
    "So what is an Agent? While the A2A protocol seems like it has been standardized, the definition of \"agent\" certainly has not. Langchain and Microsoft define an [agent](https://langchain-ai.github.io/langgraph/agents/overview/) as \"an LLM + tools + a prompt\". Google has more broadly stated that an AI agent is a software system that uses AI (not just LLMs) to proactively pursue goals and complete tasks. This allows us to expand the scope of agents to include more specialized machine learning algorithms, although the implementation of Google's agent development kit ([ADK](https://google.github.io/adk-docs/)) indicates that they really fall into the first camp. For now, I will focus on the \"LLM + tools + prompt\" definition, but stay tuned for more exploration into nuanced algorithms in the future. \n",
    "\n",
    "Let's take a look at our first \"agent\"...\n",
    "\n",
    "**Prerequisites**:\n",
    "- Pyton 3.11+\n",
    "- [Gemini API Key](https://aistudio.google.com/apikey)l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aecd0651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if not os.getenv('GOOGLE_GEMINI_API_KEY'):\n",
    "    os.environ['GOOGLE_GEMINI_API_KEY'] = 'gemini-api-key'\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cde5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "my_first_agent = Agent(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    name=\"My_first_agent\",\n",
    "    description=\"A simple agent that can call a google search\",\n",
    "    instruction=\"You are a helpful google search agent. Conduct a search when you determine it is necessary to do so.\",\n",
    "    tools=[google_search]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67cccf6",
   "metadata": {},
   "source": [
    "As you can see, there is not much effort to declare your first agent. Google's ADK abstracts away a lot of the headache. Each of the supplied parameters are pretty self-descriptive:\n",
    "- Model: the large language model used as the intelligence engine for your agent\n",
    "- Name: a descriptive name, can only contain letters, numbers and underscores\n",
    "- Description: a helpful description can go a long way, especially once multiple agents are involved in a complex process\n",
    "- Instruction: an optional system prompt that gets passed in as context to the LLM that contains any additional information or instructions\n",
    "- Tools: a list of tools an agent is capable of using. In this case we have only outfitted our agent with the ability to conduct a google search\n",
    "\n",
    "Cool, now we have now conquered the first 'A' of A2A with our primitive agent. Whats next?\n",
    "\n",
    "### Agent Executor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed1b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
