{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896f56bc",
   "metadata": {},
   "source": [
    "# A2A - a thread:\n",
    "\n",
    "### What is A2A?\n",
    "A2A is a protocol to allow AI agents to communicate autonomously amongst themselves in a standardized way. It was introduced by Google in April 2025 and donated to the Linux Foundation for more widespread adoption. As the sophistication of AI systems grows, so has the ability to automate daily tasks. However, scaling multi-agent systems has been a major bottleneck for many engineers. Frameworks like langgraph seek to solve this problem, but the framework is not very scalable and the api's don't always fit the needs of developers, can become outdated, and may introduce breaking changes...hence the need for custom agents, and modularity. A2A is an effort by Google to standardize inter-agent communication and allow developers to integrate the capabilities of various frameworks. \n",
    "\n",
    "The probabalistic origins of machine learning and AI models cause a significant amount of non-determinism in the outputs, on the contrary to traditional algorithms that provide a deterministic output (i.e. given the same input, it always produces the same output). Because of this, we can't always predict the output of a machine learning algorithm. So maybe it is obvious that in order to allow these systems to share information, the outputs must be wrapped in some metadata to provide some scaffolding for a message format, even though the messages themselves are always unique. \n",
    "\n",
    "\n",
    "See also MCP, a protocol introduced by Anthropic to provide a standard of communication between AI models and tools, data, prompts, and other resources. While MCP allows the AI \"agent\" external functionality like querying a database, searching the internet, or executing a workflow, A2A allows multiple specialized AI agents to communicate with each other and complete complex tasks by utilizing their variety of skills. If the A2A protocol reaches a critical mass, it will hopefully become the de-facto standard of communication for the new era of intelligent systems\n",
    "\n",
    "Example: Google Search Agent, Database Query agent, summarizer agent, analysis agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec7194",
   "metadata": {},
   "source": [
    "### The Agent\n",
    "\n",
    "So what is an Agent? While the A2A protocol seems like it has been standardized, the definition of \"agent\" certainly has not. Langchain and Microsoft define an [agent](https://langchain-ai.github.io/langgraph/agents/overview/) as \"an LLM + tools + a prompt\". Google has more broadly stated that an AI agent is a software system that uses AI (not just LLMs) to proactively pursue goals and complete tasks. This allows us to expand the scope of agents to include more specialized machine learning algorithms, although the implementation of Google's agent development kit ([ADK](https://google.github.io/adk-docs/)) indicates that they really fall into the first camp. For now, I will focus on the \"LLM + tools + prompt\" definition, but stay tuned for more exploration into nuanced algorithms in the future. \n",
    "\n",
    "Let's take a look at our first \"agent\"...\n",
    "\n",
    "**Prerequisites**:\n",
    "- Pyton 3.11+\n",
    "- [Gemini API Key](https://aistudio.google.com/apikey)l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aecd0651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if not os.getenv('GOOGLE_GEMINI_API_KEY'):\n",
    "    os.environ['GOOGLE_GEMINI_API_KEY'] = 'gemini-api-key'\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cde5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "my_first_agent = Agent(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    name=\"My_first_agent\",\n",
    "    description=\"A simple agent that can call a google search\",\n",
    "    instruction=\"You are a helpful google search agent. Conduct a search when you determine it is necessary to do so.\",\n",
    "    tools=[google_search]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67cccf6",
   "metadata": {},
   "source": [
    "As you can see, there is not much effort to declare your first agent. Google's ADK abstracts away a lot of the headache. Each of the supplied parameters are pretty self-descriptive:\n",
    "- Model: the large language model used as the intelligence engine for your agent\n",
    "- Name: a descriptive name, can only contain letters, numbers and underscores\n",
    "- Description: a helpful description can go a long way, especially once multiple agents are involved in a complex process\n",
    "- Instruction: an optional system prompt that gets passed in as context to the LLM that contains any additional information or instructions\n",
    "- Tools: a list of tools an agent is capable of using. In this case we have only outfitted our agent with the ability to conduct a google search\n",
    "\n",
    "Cool, now we have a primitive agent. So how do we handle messages?\n",
    "\n",
    "### Agent Executor\n",
    "The Agent Executor interface is contained in the a2a library, and provides a wrapper for the Agent to handle requests. The interface contains two main methods: `execute()`, which handles the main execution logic of the Agent's runtime and `cancel()`, which can be called during the execution of a long-running task. For now, we will focus only on `execute()`, and leave `cancel()` to a future blog. Google provides a nice implementation for a generic ADK agent in their [A2A Samples](https://github.com/a2aproject) repo that I will borrow for this example.\n",
    "\n",
    "```\n",
    "class AgentExecutor(ABC):\n",
    "    \"\"\"Agent Executor interface.\n",
    "\n",
    "    Implementations of this interface contain the core logic of the agent,\n",
    "    executing tasks based on requests and publishing updates to an event queue.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    async def execute(\n",
    "        self, context: RequestContext, event_queue: EventQueue\n",
    "    ) -> None:\n",
    "        \"\"\"Execute the agent's logic for a given request context.\n",
    "\n",
    "        The agent should read necessary information from the `context` and\n",
    "        publish `Task` or `Message` events, or `TaskStatusUpdateEvent` /\n",
    "        `TaskArtifactUpdateEvent` to the `event_queue`. This method should\n",
    "        return once the agent's execution for this request is complete or\n",
    "        yields control (e.g., enters an input-required state).\n",
    "\n",
    "        Args:\n",
    "            context: The request context containing the message, task ID, etc.\n",
    "            event_queue: The queue to publish events to.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    async def cancel(\n",
    "        self, context: RequestContext, event_queue: EventQueue\n",
    "    ) -> None:\n",
    "        \"\"\"Request the agent to cancel an ongoing task.\n",
    "\n",
    "        The agent should attempt to stop the task identified by the task_id\n",
    "        in the context and publish a `TaskStatusUpdateEvent` with state\n",
    "        `TaskState.canceled` to the `event_queue`.\n",
    "\n",
    "        Args:\n",
    "            context: The request context containing the task ID to cancel.\n",
    "            event_queue: The queue to publish the cancellation status update to.\n",
    "        \"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "The `execute()` method concurrently processes requests by keeping track of them with an `EventQueue`. Requests are presented in the form of a `RequestContext`, which contains the content of the request, along with other metadata. That is enough info for now, we will get into the weeds in future work.\n",
    "\n",
    "A critical component to the successful operation of an Agent is the `session`. A session is a stateful container that allows agents to interact asynchronously. It manages the ongoing interaction between the agents and/or users, context such as memory and state, and a request/response loop to handle communication and execution of actions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1ed1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.server.agent_execution import AgentExecutor, RequestContext\n",
    "from a2a.server.events import EventQueue\n",
    "from a2a.server.tasks import TaskUpdater\n",
    "from a2a.utils import new_task, new_agent_text_message\n",
    "from a2a.types import TaskState, TextPart, Part\n",
    "\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.artifacts import InMemoryArtifactService\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "from google.genai import types\n",
    "\n",
    "class MyAgentExecutor(AgentExecutor):\n",
    "\n",
    "    def __init__(self, agent: Agent, status_message: str = \"Executing task...\", artifact_name: str = \"response\"):\n",
    "        self.agent = agent\n",
    "        self.status_message = status_message\n",
    "        self.artifact_name = artifact_name\n",
    "        self.runner = Runner(\n",
    "            app_name=agent.name,\n",
    "            agent=agent,\n",
    "            artifact_service=InMemoryArtifactService(),\n",
    "            session_service=InMemorySessionService(),\n",
    "            memory_service=InMemoryMemoryService(),\n",
    "        )\n",
    "\n",
    "\n",
    "    async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:\n",
    "        \n",
    "        query = context.get_user_input()\n",
    "        task = context.current_task\n",
    "        if not task:\n",
    "            task = new_task(context.message)\n",
    "        \n",
    "        #enqueue a task to the event queue\n",
    "        await event_queue.enqueue_event(task)\n",
    "\n",
    "        updater = TaskUpdater(event_queue, task, task.contextId)\n",
    "\n",
    "        try:\n",
    "            await updater.update_status(\n",
    "                state=TaskState.working,\n",
    "                message=new_agent_text_message(\n",
    "                    text=\"test test\",\n",
    "                    context_id=task.contextId,\n",
    "                    task_id=task.id\n",
    "                )\n",
    "            )\n",
    "\n",
    "            session = await self.runner.session_service.create_session(\n",
    "                app_name=self.agent.name,\n",
    "                user_id=\"a2a_user\",\n",
    "                state={},\n",
    "                session_id=task.contextId,\n",
    "            )\n",
    "\n",
    "            content = types.Content(\n",
    "                role='user',\n",
    "                parts=[types.Part.from_text(query)]\n",
    "            )\n",
    "\n",
    "            response_text = \"\"\n",
    "            async for event in self.runner.run_async(\n",
    "                user_id=\"user\",\n",
    "                session_id=session.id,\n",
    "                new_message=content\n",
    "            ):\n",
    "                if event.is_final_response() and event.content and event.content.parts:\n",
    "                    for part in event.content.parts:\n",
    "                        if hasattr(part, 'text') and part.text:\n",
    "                            response_text += part.text + \"\\n\"\n",
    "                        elif hasattr(part, 'function_call'):\n",
    "                            pass\n",
    "            \n",
    "            await updater.add_artifact(\n",
    "                [Part(root=TextPart(text=response_text))],\n",
    "                name=self.artifact_name\n",
    "            )\n",
    "\n",
    "            await updater.complete()\n",
    "        \n",
    "        except Exception as e:\n",
    "            await updater.update_status(\n",
    "                TaskState.failed,\n",
    "                new_agent_text_message(f\"Error: {e!s}\", task.contextId, task.id),\n",
    "                final=True\n",
    "            )\n",
    "\n",
    "    def cancel(self, context, event_queue):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01caeb61",
   "metadata": {},
   "source": [
    "Now that we can run an agent, how do we (and more importantly other agents, since this is a blog about A2A after all...) know what its capabilities are?\n",
    "\n",
    "### Agent Card\n",
    "The agent card is a public-facing JSON schema that exposes information and metadata to clients (users and other agents). It is like a user profile, but for AI agents. To define an agent card properly, you need:\n",
    "- `name`\n",
    "- `description`: description of the agent, its skills, and other useful information\n",
    "- `version`\n",
    "- `url`: the web endpoint where we can find our agent\n",
    "- `capabilities`: supported A2A features like streaming or push notifications\n",
    "- `skills`: A pillar of A2A, the skills discovered in the `AgentCard` come in a list of `AgentSkill` objects.\n",
    "\n",
    "Lets give our agent an `AgentCard`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6881a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.types import AgentCard, AgentCapabilities\n",
    "\n",
    "agent_card = AgentCard(\n",
    "    name=my_first_agent.name,\n",
    "    description=my_first_agent.description,\n",
    "    url=\"http://localhost:9999/\",\n",
    "    version='1.0',\n",
    "    capabilities=AgentCapabilities(\n",
    "        streaming=True\n",
    "    ),\n",
    "    defaultInputModes=[\"text\", \"text/plain\"],\n",
    "    defaultOutputModes=[\"text\", \"text/plain\"],\n",
    "    skills=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce949d",
   "metadata": {},
   "source": [
    "### Agent Skills\n",
    "Agent skills describe specific capabilities the agent has, like searching the web, querying a database, executing an algorithmm...etc. Clients can find out what skills an agent has from the `AgentCard`. It's kind of like the agentic version of a resume. Skills have some attributes to define:\n",
    "- `id`: a unique id\n",
    "- `name`\n",
    "- `description`: more detailed information about the skill's functionality\n",
    "- `tags`: keywords\n",
    "- `examples`: example usage of the skill\n",
    "- `inputModes` and `outputModes`: supported modes for input and output, like text or json\n",
    "\n",
    "Let's go back and define the Google search `AgentSkill` for our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a53a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.types import AgentSkill\n",
    "\n",
    "web_search_skill = AgentSkill(\n",
    "    id='google_search',\n",
    "    name='Google Search',\n",
    "    description='Searches the web using the google_search tool',\n",
    "    tags=['web search', 'google', 'search', 'look up']\n",
    ")\n",
    "\n",
    "agent_card.skills.append(web_search_skill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a48fa4",
   "metadata": {},
   "source": [
    "Now our agent has advertized the ability to search the web on its agent card. We will take a deep dive into `AgentSkill`s, `AgentCapabilities`, and `AgentCard`s another time, but now lets zoom out a little bit. We have given lots of detail about our agent. Where it lives, what it can do, examples for how to use it... So how do we run it and start testing this stuff out?\n",
    "\n",
    "### Starting the Server\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc01fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from a2a.server.request_handlers import DefaultRequestHandler\n",
    "from a2a.server.tasks import InMemoryTaskStore\n",
    "from a2a.server.apps import A2AStarletteApplication\n",
    "\n",
    "request_handler = DefaultRequestHandler(\n",
    "    agent_executor=MyAgentExecutor(my_first_agent),\n",
    "    task_store=InMemoryTaskStore()\n",
    ")\n",
    "\n",
    "server = A2AStarletteApplication(\n",
    "    agent_card=agent_card,\n",
    "    http_handler=request_handler,\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
